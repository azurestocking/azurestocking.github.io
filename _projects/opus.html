---
layout: project
slug: opus
featured: true
title: "Lorem ipsum dolor sit amet, consectetur adipiscing elit"
desc: "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
impact: "Lorem ipsum dolor sit amet consectetur adipiscing elit. Consectetur adipiscing elit quisque faucibus ex sapien vitae. Ex sapien vitae pellentesque sem placerat in id. Placerat in id cursus mi pretium tellus duis. Pretium tellus duis convallis tempus leo eu aenean."
image: "/images/placeholder.jpg"
color: "#EBEAFA"
duration: "Mar 2024 - Jun 2024"
tags:
  - Design
  - Web
  - Generative AI
  - Technology
role:
  - Product Designer
team:
  - 2 Product Designers
  - 1 Product Manager
skill:
  - Market Research
  - Product Strategy
  - Rapid Prototyping
  - User Research
tool:
  - Figma
---

<section>
    <h3>Background</h3>
    <div class="grid grid-2-0">
        <div>
            <p>The team needed to quickly and affordably validate a loosely defined but potentially valuable opportunity without diverting core production efforts. Therefore, as an external consultant, I was brought in to lead a focused rapid prototyping sprint, navigating ambiguity and trust issues amid limited support, vague requirements, and low internal priority.</p>
        </div>
    </div>
    <div class="grid grid-3">
        <div class="card">
            <h5>üí∞ Tight Budget</h5>
            <p>The company is an early-stage startup preparing for Series A with a small team and limited resources, lacking bandwidth for a full-time hire.</p>
        </div>
        <div class="card">
            <h5>üí™ Fueling Market</h5>
            <p>The company is among the earliest players in AI-assisted captioning, but the space has a low barrier to entry, making differentiation more critical.</p>
        </div>
        <div class="card">
            <h5>ü§ù Potential Synergy</h5>
            <p>The company has received feedback requesting a text-to-video feature, indicating a strong synergy with existing capabilities and user base.¬†</p>
        </div>
    </div>
</section>

<section>
    <h3>Challenge</h3>
    <div class="grid grid-2-0">
        <div>
            <p>We set off with a knowingly over-simplistic problem framing that lacks the clear understanding of user needs, workflows, or success criteria:</p>
        </div>
    </div>
    <div class="grid grid-1">
        <div class="card">
            <div class="p-l" style="margin-bottom: 0px;">
                <blockquote>How might we integrate a text-to-video feature into our product?</blockquote>
            </div>
        </div>
        
    </div>
    <div class="grid grid-2-0">
        <div>
            <p>Don‚Äôt be hasty to frown! In the subsequent design cycles, we used prototype-based testing to elicit user feedback, surfacing real needs and progressively clarifying the problem space:</p>
        </div>
    </div>
    <div class="grid grid-1">
        <div class="card">
            <div class="p-l" style="margin-bottom: 0px;">
                <blockquote>How might we empower content creators to quickly and easily translate their scripts into reliably high-quality videos while accommodating diverse scenarios?</blockquote>
            </div>
        </div>
    </div>
</section>

<section>
    <h3>Solution</h3>
    <div class="p-l">
        We proposed an end-to-end tool for AI video production, built on a multistage generative media pipeline focused on collaborative workflow enhancement rather than dependence on powerful models, enabling faster iteration, consistent output, and creative control from scripting to shot management.
    </div>
</section>

<section>
    <div class="grid grid-1" style="margin-top: 0px;">
        <video width="100%" height="auto" autoplay loop muted>
            <source src="/images/opus/F1.mp4" type="video/mp4" loading="lazy">
        </video>
    </div>
    <div class="grid grid-2-0">
        <div>
            <h4>I. Collaborative Script Editor</h4>
            <p style="margin-bottom: 1em;">Allows users to select and modify text segments using predefined AI enhancement functions or instruction-based prompts without altering adjacent content. </p>
            <p>Enables easy formatting aligned with industry-standard screenplay conventions to structurally differentiate key elements, improving token-level disambiguation, model output accuracy, and readability.</p>
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1" style="margin-top: 0px;">
        <video width="100%" height="auto" autoplay loop muted>
            <source src="/images/opus/F2.mp4" type="video/mp4" loading="lazy">
        </video>
    </div>
    <div class="grid grid-2-0">
        <div>
            <h4>II. Adaptive Shot Manager</h4>
            <p>Serves as a visual intermediary between text and video generation through a keyframe-based storyboard.</p>
            <p>Supports three distinct modes for flexible shot management at varying levels of granularity: thumbnail, editor, and slideshow modes, respectively for navigation, refinement, and preview, covering the full production lifecycle.</p>
            <p>Includes key element filters to improve manageability in complex or long-form screenplays.</p>
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1" style="margin-top: 0px;">
        <video width="100%" height="auto" autoplay loop muted>
            <source src="/images/opus/F3.mp4" type="video/mp4" loading="lazy">
        </video>
    </div>
    <div class="grid grid-2-0">
        <div>
            <h4>III. Comprehensive Shot Editor</h4>
            <p>Provides full-spectrum yet atomic control over individual shots, including keyframes, audio, and camera movement.</p>
            <p>Utilizes a context-aware interface with inline dropdowns and modals to enable seamless interaction without disrupting the editing flow.</p>
            <p>Adopts a hybrid editing approach that combines manual input with AI assistance, enhancing productivity while preserving creative autonomy.</p>
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1" style="margin-top: 0px;">
        <video width="100%" height="auto" autoplay loop muted>
            <source src="/images/opus/F4.mp4" type="video/mp4" loading="lazy">
        </video>
    </div>
    <div class="grid grid-2-0">
        <div>
            <h4>IV. Customizable Asset Manager</h4>
            <p>Creates a centralized system by extracting reusable global assets from natural language through semantic parsing, allowing them to be defined, applied to individual shots, and batch-edited across multiple shots. It enhances consistency and scalability for large-scale and episodic productions, and optimizes workflows by reducing duplication and manual effort.</p>
        </div>
    </div>
</section>

<section>
    <h2>Design Process</h2>
    <div class="p-l">
        We adopted a Lean approach to move quickly and stay focused on real user needs, using iterative prototyping to validate assumptions and evaluate outcomes, thereby enabling confident product direction without overcommitting resources.
    </div>
    <div class="grid grid-1">
        <div class="image-container">
            <img src="{{ '/images/opus/design-process.png' | relative_url }}" loading="lazy">
        </div>
    </div>
</section>

<section>
    <h3>Market Analysis</h3>
    <div class="grid grid-2-0">
        <div>
            <p>Leading players appeared to focus on generating impressive but disjointed video clips, placing less emphasis on connecting them into structured narrative, which positions themselves more as tools for visual experimentation and asset creation.</p>
            <p>To validate this hypothesis, I identified several leading players along the production cycle and established a set of criteria to assess their narrative capabilities.</p>
        </div>
    </div>
    <div class="grid grid-1">
        <div class="image-container">
            <img src="{{ '/images/opus/market-analysis.png' | relative_url }}" loading="lazy">
        </div>
    </div>
</section>

<section>
    <h3>Brainstorming</h3>
    <div class="grid grid-2-0">
        <div>
            <p>The matrix above reveals a strategic opportunity: to differentiate by centering on storytelling support, aligning with the market gap and the team‚Äôs strengths, instead of competing on model performance.</p>
            <p>We brainstormed features that address narrative structure and creative flow more directly than model-centric competitors, using a mind map. Those deemed technically feasible and within design scope were marked as low-hanging fruit.</p>
        </div>
    </div>
    <div class="grid grid-1">
        <div class="image-container">
            <img src="{{ '/images/opus/brainstorming.png' | relative_url }}" loading="lazy">
        </div>
    </div>
</section>

<section>
    <h3>Wireframe</h3>
    <div class="grid grid-2">
        <div>
            <img src="{{ '/images/placeholder.jpg' | relative_url }}" loading="lazy">
        </div>
        <div>
            <img src="{{ '/images/placeholder.jpg' | relative_url }}" loading="lazy">
        </div>
    </div>
    <div class="grid grid-2">
        <div>
            <h5>Storyboard</h5>
            <p>A visual tool used by filmmakers and animators to pre-visualize and plan a production clearly and efficiently, e.g., Toon Boom Storyboard.</p>
        </div>
        <div>
            <h5>Infinite Canvas</h5>
            <p>A modular approach used by domain experts to design and execute complex systems visually, e.g., Grasshopper, Unreal Engine.</p>
        </div>
    </div>
</section>

<section>
    <h3>Concept Testing</h3>
    <div class="grid grid-2-0">
        <div>
            <p>Although the cell option initially appealed to the team‚Äôs intellectual curiosity, I facilitated an asynchronous workshop to gather insights cross-functionally and evaluate its viability.</p>
        </div>
    </div>
    <div class="grid grid-1">
        <div class="image-container">
            <img src="{{ '/images/opus/concept-testing.png' | relative_url }}" loading="lazy">
        </div>
    </div>
</section>

<section>
    <h3 class="np">Insights</h3>
    <div class="grid grid-2-0">
        <div>
            <p>Insights gathered and synthesized through affinity mapping revealed that implementing such an architecture would require substantial engineering refactoring and invited critical concerns across technical, usability, and strategic dimensions.</p>
        </div>
    </div>
    <div class="grid grid-3">
        <div class="card">
            <h5>ü§π Technical Complexity</h5>
            <p>Requires each cell to be developed standalone yet communicative, and the magnitude of potential cell combinations exponentially poses challenges in scalability, agility, and version control.</p>
        </div>
        <div class="card">
            <h5>ü§Ø Usability Uncertainty</h5>
            <p>Introduces flexibility with larger possibility of choice paralysis and increased cognitive load, which may alienate users with a fragmented, unpredictable, and delayed experience.</p>
        </div>
        <div class="card">
            <h5>üìâ Managerial Misalignment</h5>
            <p>Demands significant resources in labor, capital, and time for development and operation, potentially resulting in delays, shifts, or failures in achieving long-term strategic goals.</p>
        </div>
    </div>
</section>

<section>
    <h3>Prototype 1</h3>
    <div class="grid grid-1">
        <img src="{{ '/images/opus/prototype-1.png' | relative_url }}" loading="lazy" style="background-color: var(--ghost);">
    </div>
</section>

<section>
    <h3>Usability Testing 1</h3>
    <div class="grid grid-2-0">
        <div>
            <p>Since I hypothesized multiple user segments, I recruited a slightly larger and diverse sample of 8 participants, including vloggers, content aggregators, enterprise marketers, and filmmakers.</p>
            <p>I tested this prototype to identity the main usability and functionality issues, along with a screener survey to assess the <b>usage intensity</b>, i.e., how each participant might use the proposed feature in their routine.</p>
        </div>
    </div>
    <div class="grid grid-1">
        <div class="image-container">
            <img src="{{ '/images/opus/usability-testing-1-1.png' | relative_url }}" loading="lazy">
        </div>
    </div>
</section>

<section>
    <h3 class="np">Insights</h3>
    <div class="grid grid-2-0">
        <div>
            <p>Looking closely, I found that even feedback within the same group often expressed conflicting views on what needed improvement.</p>
            <p>To make sense of those seemingly irreconcilable contradictions, I first examined the underlying intent behind each request, and then reshuffled them by <b>high-level goals</b>‚Äîthe broader needs encompassing possibly divergent user behaviors and expectations.</p>
        </div>
    </div>
    <div class="grid grid-3">
        <div class="card">
            <h5>‚åõÔ∏è Efficiency</h5>
            <p>Reduce time, effort, financial cost, and cognitive friction by providing readable information, an intuitive interface, and a streamlined, user-friendly workflow.</p>
        </div>
        <div class="card">
            <h5>üìê Consistency</h5>
            <p>Enable a coherent narrative and stable visual identity across frames, while allowing reasonable variation to support continuity in action, time, and space.</p>
        </div>
        <div class="card">
            <h5>üïπ Adaptability</h5>
            <p>Support varied intents and use cases through rich customization options, flexible control over outputs and workflows, and a context-aware, responsive system.</p>
        </div>
    </div>
</section>

<section>
    <h3>Problem Statement</h3>
    <div class="grid grid-2-0">
        <div>
            <p>With the shared high-level goals that emerged above, I was able to refine the initially rough question as follows:</p>
        </div>
    </div>
    <div class="grid grid-1">
        <div class="card">
            <div class="p-l" style="margin-bottom: 0px;">
                <blockquote>How might we empower content creators to quickly and easily translate their scripts into reliably high-quality videos while accommodating diverse scenarios?</blockquote>
            </div>
        </div>
    </div>
</section>

<section>
    <h3 class="np">Insights</h3>
    <div class="grid grid-2-0">
        <div>
            <p>The observed conflicting feedback unveiled divergent user expectations and behaviors, rooted in how users conceptualized the shared high-level goals differently and hence their distinct positions on value trade-offs. This indicates multiple user segments, which should be logically inferable by their clustering on these trade-off spectrums.</p>
            <p>Therefore, I mapped all those stickers onto two axes that represent core tensions in users‚Äô decision-making: <b>Cost vs. Perceived Quality</b> and <b>User Agency vs. Automation</b>.</p>
        </div>
    </div>
    <div class="grid grid-1">
        <div class="image-container">
            <img src="{{ '/images/opus/usability-testing-1-2.png' | relative_url }}" loading="lazy">
        </div>
    </div>
    <div class="grid grid-2-0">
        <div>
            <p>All feedback is distributed diagonally from the upper-left to lower-right quadrants, with high and low usage intensity clustering at opposite ends, leading to the following insights:</p>
        </div>
    </div>
    <div class="grid grid-2">
        <div class="card">
            <h5>1Ô∏è‚É£ We Don‚Äôt Trust AI</h5>
            <p>The negative correlation between perceived quality and automation validates the hypothesis that users associate strong outputs with manual control, implying limited trust in fully automated systems to deliver professional results.</p>
        </div>
        <div class="card">
            <h5>2Ô∏è‚É£ User Segmentation</h5>
            <p>The polarization between users with different usage intensity reveals two user groups that vary in positions on the two axes, i.e., the expectation for production commitment and outcomes, and the preference for interaction.</p>
        </div>
    </div>
</section>

<section>
    <h3>Personas</h3>
    <div class="grid grid-2-0">
        <div>
            <p>Based on these insights, I developed two personas and visualized their differences across multiple dimensions of the two spectrums.</p>
        </div>
    </div>
    <div class="grid grid-2">
        <div>
            <img src="{{ '/images/opus/persona-1.png' | relative_url }}" loading="lazy">
        </div>
        <div>
            <img src="{{ '/images/opus/persona-2.png' | relative_url }}" loading="lazy">
        </div>
    </div>
    <div class="grid grid-2">
        <div>
            <h5>Original Creator</h5>
            <p>Likely content creators with a high level of expertise, such as indie filmmakers and animators; seek to maintain creative authorship while achieving high-quality outputs; cautious of full automation and perceive the tool as an extension.</p>
        </div>
        <div>
            <h5>Derivative Creator</h5>
            <p>Likely content creators with distribution-driven priorities, such as influencers and content aggregators; aim to produce acceptable outputs with minimal input; willing to delegate complex tasks to the system and view the tool as a replacement.</p>
        </div>
    </div>
</section>

<section>
    <h3>Prototype 2</h3>
    <div class="p-l">
        We improved clarity and workflow efficiency through both structural and functional enhancements, including a redesigned layout, surfaced global settings, and centralized asset control to support faster, more consistent text-to-image generation.
    </div>
</section>

<section>
    <h4>I. Layout</h4>
    <div class="grid grid-2">
        <div class="before">
            <img src="{{ '/images/opus/I1-1B.png' | relative_url }}" loading="lazy">
        </div>
        <div class="after">
            <video width="100%" height="auto" autoplay loop muted>
                <source src="/images/opus/I1-1A.mp4" type="video/mp4" loading="lazy">
            </video>
        </div>
    </div>
    <div class="grid grid-2">
        <div class="before">
            <h5>BEFORE</h5>
            <p>Arranged shots horizontally, causing confusion due to misalignment between the container and slider, and conflicting with the standard scrolling pattern.</p>
        </div>
        <div class="after">
            <h5>AFTER</h5>
            <p>Restructured editor mode with vertical arrangement, hover effects, and collapsible tabs to reduce cognitive load through prioritized information display.</p>
        </div>
    </div>
</section>

<section>
    <h4>II. Customizable Assets</h4>
    <div class="grid grid-2">
        <div class="before">
            <img src="{{ '/images/opus/I1-2-1B.png' | relative_url }}" loading="lazy">
        </div>
        <div class="after">
            <img src="{{ '/images/opus/I1-2-1A.png' | relative_url }}" loading="lazy">
        </div>
    </div>
    <div class="grid grid-2">
        <div class="before">
            <h5>BEFORE</h5>
            <p>Configured global setting options manually each time through a low-discoverability button, leading to repetitive setup and frequent oversight.</p>
        </div>
        <div class="after">
            <h5>AFTER</h5>
            <p>Presented global settings in a conspicuous sidebar and enabled predefined and customizable templates to streamline setup and ensure consistency.</p>
        </div>
    </div>
    <div class="grid grid-2">
        <div class="before">
            <img src="{{ '/images/opus/I1-2-2B.png' | relative_url }}" loading="lazy">
        </div>
        <div class="after">
            <video width="100%" height="auto" autoplay loop muted>
                <source src="/images/opus/I1-2-2A.mp4" type="video/mp4" loading="lazy">
            </video>
        </div>
    </div>
    <div class="grid grid-2">
        <div class="before">
            <h5>BEFORE</h5>
            <p>Required extensive manual effort to tweak shots individually in order to maintain visual consistency across shots.</p>
        </div>
        <div class="after">
            <h5>AFTER</h5>
            <p>Extracted shared assets from the script automatically, enabling centralized control for easy insertion and batch-level tweaking.</p>
        </div>
    </div>
</section>

<section>
    <h4>III. Script Editing</h4>
    <div class="grid grid-2">
        <div class="before">
            <img src="{{ '/images/opus/I1-3B.png' | relative_url }}" loading="lazy">
        </div>
        <div class="after">
            <img src="{{ '/images/opus/I1-3A.png' | relative_url }}" loading="lazy">
        </div>
    </div>
    <div class="grid grid-2">
        <div class="before">
            <h5>BEFORE</h5>
            <p>Applied AI-assisted text refinement to the entire text area, altering unrelated content and lacking support for targeted, precise control.</p>
        </div>
        <div class="after">
            <h5>AFTER</h5>
            <p>Introduced a floating toolbar that enables users to select specific text segments in the editor, supporting focused, instructional modifications.</p>
        </div>
    </div>
</section>

<section>
    <h4>IV. Separate Workflow</h4>
    <div class="grid grid-2">
        <div class="before">
            <img src="{{ '/images/opus/I1-4B.png' | relative_url }}" loading="lazy" style="background-color: var(--ghost);">
        </div>
        <div class="after">
            <img src="{{ '/images/opus/I1-4A.png' | relative_url }}" loading="lazy" style="background-color: var(--ghost);">
        </div>
    </div>
    <div class="grid grid-2">
        <div class="before">
            <h5>BEFORE</h5>
            <p>Followed a linear path with a fixed entry point, assuming all users start from scratch and proceed through every editing stage.</p>
        </div>
        <div class="after">
            <h5>AFTER</h5>
            <p>Added conditional branching and early skip options to bypass unnecessary editing steps based on user readiness, reducing the minimum required steps.</p>
        </div>
    </div>
</section>

<section>
    <h3>Usability Testing 2</h3>
    <div class="grid grid-2-0">
        <div>
            <p>I tested the updated prototype and initially categorized feedback by improvement areas. I then reclassified it using the previously identified high-level goals. However, several items didn‚Äôt fit any known category.</p>
        </div>
    </div>
    <div class="grid grid-1">
        <div class="image-container">
            <img src="{{ '/images/opus/usability-testing-2.png' | relative_url }}" loading="lazy">
        </div>
    </div>
</section>

<section>
    <h3 class="np">Insights</h3>
    <div class="grid grid-2-0">
        <div>
            <p>The uncategorized feedback reveals an unstated high-level goal in the previous round, i.e., <b>transparency</b>‚Äîa deeper understanding of the system‚Äôs operations and decisions, and hence more informed and targeted manipulation.</p>
        </div>
    </div>
    <div class="grid grid-3">
        <div class="card">
            <h5>1Ô∏è‚É£ Expose Processing Logic</h5>
            <p>Demystify how inputs and parameters are interpreted, e.g., establish a visually clear cause-effect relationship between script segments and corresponding generated shots.</p>
        </div>
        <div class="card">
            <h5>2Ô∏è‚É£ Guide Interactions</h5>
            <p>Offer proactive cues to achieve desired outcomes, e.g., simplify complex, effort-intensive prompting by disassembling it into smaller, manageable pieces via structured input fields.</p>
        </div>
        <div class="card">
            <h5>3Ô∏è‚É£ Enable Human Oversight</h5>
            <p>Integrate deliberate review points where users can validate, adjust, or regenerate AI outputs, e.g., include undo/redo capabilities and history log to revert states or track changes.</p>
        </div>
    </div>
</section>

<section>
    <h3>Prototype 3</h3>
    <div class="p-l">
        We included transparency as a new evaluation lens while continuing to improve core usability through fine-grained refinements, including clarified interface hierarchy and interaction logic, flexible preview controls, and more informative version tracking.
    </div>
</section>

<section>
    <h4>I. Script Editing</h4>
    <div class="grid grid-2">
        <div class="before">
            <video width="100%" height="auto" autoplay loop muted>
                <source src="/images/opus/I2-1-1B.mp4" type="video/mp4" loading="lazy">
            </video>
        </div>
        <div class="after">
            <video width="100%" height="auto" autoplay loop muted>
                <source src="/images/opus/I2-1-1A.mp4" type="video/mp4" loading="lazy">
            </video>
        </div>
    </div>
    <div class="grid grid-2">
        <div class="before">
            <h5>BEFORE</h5>
            <p>Relied on plain text with minimal markdown-style grammar, confusing non-technical users and necessitating model‚Äôs semantic understanding.</p>
        </div>
        <div class="after">
            <h5>AFTER</h5>
            <p>Added a reformat option to declare key elements with symbolic tags for frontend styling and generative performance.</p>
        </div>
    </div>
    <div class="grid grid-2">
        <div class="before">
            <video width="100%" height="auto" autoplay loop muted>
                <source src="/images/opus/I2-1-2B.mp4" type="video/mp4" loading="lazy">
            </video>
        </div>
        <div class="after">
            <video width="100%" height="auto" autoplay loop muted>
                <source src="/images/opus/I2-1-2A.mp4" type="video/mp4" loading="lazy">
            </video>
        </div>
    </div>
    <div class="grid grid-2">
        <div class="before">
            <h5>BEFORE</h5>
            <p>Used buttons with leading icons and labels for all options and a slider to adjust tone and length, resulting in redundant choices and unnecessary clicks.</p>
        </div>
        <div class="after">
            <h5>AFTER</h5>
            <p>Simplified and grouped buttons with icons and tooltips, differentiated prompt input, and removed unnecessary two-step interactions.</p>
        </div>
    </div>
</section>

<section>
    <h4>II. Shot Editing</h4>
    <div class="grid grid-2">
        <div class="before">
            <img src="{{ '/images/opus/I2-2-1B.png' | relative_url }}" loading="lazy" style="background-color: var(--ghost);">
        </div>
        <div class="after">
            <img src="{{ '/images/opus/I2-2-1A.png' | relative_url }}" loading="lazy" style="background-color: var(--ghost);">
        </div>
    </div>
    <div class="grid grid-2">
        <div class="before">
            <h5>BEFORE</h5>
            <p>Misarranged controls with miscellaneous information architecture, juxtaposing hierarchical functions and nesting parallel ones.</p>
        </div>
        <div class="after">
            <h5>AFTER</h5>
            <p>Reorganized controls by target objects and logical relationships across the floating toolbar and modal, and removed redundant buttons.</p>
        </div>
    </div>
    <div class="grid grid-2">
        <div class="before">
            <img src="{{ '/images/opus/I2-2-2B.png' | relative_url }}" loading="lazy">
        </div>
        <div class="after">
            <img src="{{ '/images/opus/I2-2-2A.png' | relative_url }}" loading="lazy">
        </div>
    </div>
    <div class="grid grid-2">
        <div class="before">
            <h5>BEFORE</h5>
            <p>Opened a separate page with a disjointed layout where the trigger button didn‚Äôt align with the output keyframe, causing confusion about source and result.</p>
        </div>
        <div class="after">
            <h5>AFTER</h5>
            <p>Flattened the page hierarchy with modals and in-textarea select dropdowns to create intuitive cause-and-effect relationship.</p>
        </div>
    </div>
    <div class="grid grid-2">
        <div class="before">
            <img src="{{ '/images/opus/I2-2-3B.png' | relative_url }}" loading="lazy">
        </div>
        <div class="after">
            <video width="100%" height="auto" autoplay loop muted>
                <source src="/images/opus/I2-2-3A.mp4" type="video/mp4" loading="lazy">
            </video>
        </div>
    </div>
    <div class="grid grid-2">
        <div class="before">
            <h5>BEFORE</h5>
            <p>Generated audio tracks solely from voiceover input, limiting support to genres like vlogs and commentary where narrative and visuals are closely aligned.</p>
        </div>
        <div class="after">
            <h5>AFTER</h5>
            <p>Distinguished dialogue from voiceover to accommodate feature films where audio diverges from visuals and voiceover alone is thus insufficient.</p>
        </div>
    </div>
</section>

<section>
    <h4>III. Transparency</h4>
    <div class="grid grid-2">
        <div class="before">
            <img src="{{ '/images/opus/I2-3-1B.png' | relative_url }}" loading="lazy">
        </div>
        <div class="after">
            <video width="100%" height="auto" autoplay loop muted>
                <source src="/images/opus/I2-3-1A.mp4" type="video/mp4" loading="lazy">
            </video>
        </div>
    </div>
    <div class="grid grid-2">
        <div class="before">
            <h5>BEFORE</h5>
            <p>Restricted preview access to the final step behind an ambiguous button, with no option to specify starting points, discouraging early risk identification.</p>
        </div>
        <div class="after">
            <h5>AFTER</h5>
            <p>Introduced a slideshow mode that simulates the final output‚Äôs pacing and structure before committing, with flexible back-and-forth switching between modes.</p>
        </div>
    </div>
    <div class="grid grid-2">
        <div class="before">
            <img src="{{ '/images/opus/I2-3-2B.png' | relative_url }}" loading="lazy">
        </div>
        <div class="after">
            <img src="{{ '/images/opus/I2-3-2A.png' | relative_url }}" loading="lazy">
        </div>
    </div>
    <div class="grid grid-2">
        <div class="before">
            <h5>BEFORE</h5>
            <p>Kept a flat version control system that recorded all generation variations, providing little value for tracking meaningful changes or refining prompts.</p>
        </div>
        <div class="after">
            <h5>AFTER</h5>
            <p>Maintained an iteration log that highlights differences compared to the last selected version, enabling more informed and focused revisions.</p>
        </div>
    </div>
</section>

<section>
    <h2>Retrospect</h2>
    <div class="p-l">
        Trust-building surfaced as a recurring theme, not only in designing human-AI collaborative models that foster user confidence, but also in establishing credibility and exposure within the team, thereby driving iterative direction and securing alignment as a mercenary with limited visibility and resources.
    </div>
</section>

<section>
    <h3>Takeaways</h3>
    <div class="grid grid-2-0">
        <div>
            <p>Looking back, my problem statement and persona were made as logically required steps emerging organically from the iterative, user-centric prototype testing and analysis, rather than predefined JTBDs adhering to a dogmatic ‚Äúdiscovery‚Äù framework in the beginning.</p>
            <p>Besides, key insights emerged not only about users‚Äô mental models and behaviors, but also about coping with vagueness in social dynamics, research methodologies, and practical techniques.</p>
        </div>
    </div>
    <div class="grid grid-3">
        <div class="card">
            <h5>1Ô∏è‚É£ Billiard Method</h5>
            <p>When direct peer support is absent, maintain momentum by engaging stand-by colleagues with something tangible in hands for constructive feedback.</p>
        </div>
        <div class="card">
            <h5>2Ô∏è‚É£ Upfront Benchmarking</h5>
            <p>When A/B testing isn‚Äôt available for multiple choices, define evaluative criteria that derive from core objectives with specific, actionable, and measurable rubrics.</p>
        </div>
        <div class="card">
            <h5>3Ô∏è‚É£ Opening Black Box</h5>
            <p>Provide transparency into AI‚Äôs decision-making, rather than simply presenting end-products, allowing users to understand how inputs translate into outputs.</p>
        </div>
    </div>
</section>

<section>
    <h3>Ways Forward</h3>
    <div class="grid grid-2-0">
        <div>
            <p>Looking ahead, our future endeavors should take a holistic consideration of various dimensions in design, development, and strategy, to adapt to evolving product demands and market dynamics.</p>
        </div>
    </div>
    <div class="grid grid-3">
        <div class="card">
            <h5>1Ô∏è‚É£ Waiting Experience</h5>
            <p>Implement mechanisms like progressive disclosure or dynamic skeleton, keeping users engaged during processing time, reducing perceived latency.</p>
        </div>
        <div class="card">
            <h5>2Ô∏è‚É£ Compatibility</h5>
            <p>Integrate with existing captioning workflows and seamlessly merge into the broader post-production ecosystem by enabling export to popular NLEs.</p>
        </div>
        <div class="card">
            <h5>3Ô∏è‚É£ Pricing Structure</h5>
            <p>Explore new monetization strategies that fit increased computational costs and value delivered, e.g., tiered subscriptions, pay-per-export, and enterprise licensing.</p>
        </div>
    </div>
</section>