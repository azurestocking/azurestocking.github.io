---
layout: project
slug: opus
featured: true
title: "Orchestrating Storytelling for Content Creators with Integrated Video Generation Workflow"
desc: "Opus was a Pre-Series A startup aiming to integrate a text-to-video generation feature into its current product amid limited resources and intensifying market. Our research yielded data-driven insights through iterative prototype-based testing, uncovering diverse user segments and their varied expectations and shared high-level goals, culminating in a design proposal for an end-to-end, human-AI collaborative storytelling support tool."
problem: "Faced a twofold challenge: to strategically validate this opportunity by defining a compelling value proposition and identifying key user segments, and technically, to align the feature with actual user workflows in design."
outcome: "Earned 3 top-tier design awards, boosting the client‚Äôs profile for the later $30M Series A fundraising. Served as an internal reference that guides the subsequent product development and strategic roadmap."
image: "/images/placeholder-rectangle.png"
color: "#EBEAFA"
time: "June 2024"
categories:
  - Design
tags:
  - Design
  - Web
  - Generative AI
  - Technology
role:
  - Product Designer
team:
  - 1 Product Designer
  - 1 Product Manager
skill:
  - Market Research
  - Product Strategy
  - Rapid Prototyping
  - User Research
tool:
  - Figma
links:
  - #highlight
---

<section>
    <div class="grid grid-1-3-1-1">
        <div></div>
        <div>
            <h3>Background</h3>
            <p>The team needed to quickly and affordably validate a loosely defined but potentially valuable opportunity without diverting core production efforts. I was brought in to lead a focused rapid prototyping sprint under low internal priority.</p>
        </div>
    </div>
    <div class="grid grid-1-4-1">
        <div></div>
        <div class="card-list">
            <div class="card">
                <h5>üíµ Limited Resource</h5>
                <p>The company was an early-stage startup preparing for Series A, operating with a small team and limited budget, and lacking the bandwidth to make a full-time hire for temporary concept testing.</p>
            </div>
            <div class="card">
                <h5>üí™ Growing Market</h5>
                <p>The company is among the earliest players in AI-powered video captioning and repurposing, but the low barrier to entry makes differentiation essential to maintain its competitive edge as more industry giants enter the space, such as OpenAI Sora, Adobe Firefly, and ByteDance CapCut.</p>
            </div>
            <div class="card">
                <h5>ü§ù Potential Synergy</h5>
                <p>Users have expressed strong interest in text-to-video generation, which has the potential to create meaningful synergy with the existing capability, enhancing overall value within a unified workflow.</p>
            </div>
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-3-1-1">
        <div></div>
        <div>
            <h3>Challenge</h3>
            <p>Amidst the AIGC boom, integrating a text-to-video feature seemed timely and feasible. Yet, the go-to-market challenge wasn‚Äôt about design implementation alone; it lay in clarifying strategic ambiguity‚Äîspecifically, articulating a compelling value proposition, identifying the right user segments, and aligning with actual workflows to drive profitable adoption.</p>
        </div>
    </div>
    <div class="grid grid-1-4-1">
        <div></div>
        <div class="p-l" style="margin-bottom: 0px;">
            <blockquote>How might we empower content creators to quickly and easily translate their scripts into reliably high-quality videos while accommodating diverse scenarios?</blockquote>
        </div>
    </div>
</section>

<section id="highlight">
    <div class="grid grid-1-4-1">
        <div></div>
        <div>
            <h3>Highlight</h3>
            <div class="p-l">
                Proposed an end-to-end storytelling support tool for AI video production, built on a multistage generative media pipeline focused on human-AI collaborative workflow enhancement rather than dependence on powerful models, enabling faster iteration, consistent output, and flexible control.
            </div>
        </div>
    </div>
</section>

<section class="full-width-bg" style="background-color: {{ page.color }};">
    <div class="grid grid-6">
        <h4>I. Collaborative Script Composition</h4>
    </div>
    <div class="grid grid-6">
        {% include mockup-macbook.html 
            content_image="/images/opus/F1.mp4" 
            content_type="video" %}
    </div>
    <div class="grid grid-3-3">
        <div>
            <h5>Precise Text Enhancement</h5>
            <p>Users can select and refine specific text segments using predefined functions such as polish, shorten, and regenerate, or apply custom instruction-based prompts, all while ensuring adjacent content remains unaffected.</p>
        </div>
        <div>
            <h5>Easy Screenplay Reformatting</h5>
            <p>Users can reformat scripts adhering to industry-standard conventions, which structurally distinguishes key elements like action, dialogue, character, and transition, improving readability and enhancing LLM understanding.</p>
        </div>
    </div>

    <div class="grid grid-6">
        <h4>II. Flexible Storyboard Management</h4>
    </div>
    <div class="grid grid-6">
        {% include mockup-macbook.html 
            content_image="/images/opus/F2.mp4" 
            content_type="video" %}
    </div>
    <div class="grid grid-3-3">
        <div>
            <h5>Adaptive View Modes</h5>
            <p>Users can switch between varying levels of granularity using three distinct view modes: thumbnail for navigation, editor for detailed refinement, and slideshow for preview, covering the full production lifecycle.</p>
        </div>
        <div>
            <h5>Targeted Shot Focus</h5>
            <p>Users can apply key element filters to isolate shots by character or scene, enabling focused editing, reduced visual clutter, and improved manageability within complex or long-form scripts.</p>
        </div>
    </div>

    <div class="grid grid-6">
        <h4>III. Comprehensive Shot Tweaking</h4>
    </div>
    <div class="grid grid-6">
        {% include mockup-macbook.html 
            content_image="/images/opus/F3.mp4" 
            content_type="video" %}
    </div>
    <div class="grid grid-3-3">
        <div>
            <h5>Complete Production Control</h5>
            <p>Users can fine-tune keyframes using a full set of tools, such as reprompting, uploading, generative fill, and camera movement setting, and edit voiceover and dialogue transcripts.</p>
        </div>
        <div>
            <h5>Accessible Prompt Builder</h5>
            <p>Users can transform complex, text-based prompting into an intuitive, GUI-driven experience with structured, atomic controls to achieve desired results without prompt engineering expertise, lowering the cognitive burden.</p>
        </div>
    </div>

    <div class="grid grid-6">
        <h4>IV. Centralized Asset Management & Customization</h4>
    </div>
    <div class="grid grid-6">
        {% include mockup-macbook.html 
            content_image="/images/opus/F4.mp4" 
            content_type="video" %}
    </div>
    <div class="grid grid-3-3">
        <div>
            <h5>Automatic Entity Extraction</h5>
            <p>Users no longer need to manually identify reusable characters and scenes, as the model automatically extracts global assets from natural language input using advanced semantic parsing.</p>
        </div>
        <div>
            <h5>Centralized Asset Manager</h5>
            <p>Users can update multiple shots in batch by customizing shared global assets through a centralized system, accelerating revisions and ensuring visual consistency across the entire project.</p>
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-4-1">
        <div></div>
        <div>
            <h2>Design Process</h2>
            <div class="p-l">
                Adopted a Lean approach to move quickly and stay focused on user needs, using iterative prototyping to validate assumptions and evaluate outcomes, thereby enabling confident product direction without overcommitting resources.
            </div>
        </div>
    </div>
    <div class="grid grid-1-4-1">
        <div></div>
        <div class="image-container">
            <img src="{{ '/images/opus/design-process.png' | relative_url }}" loading="lazy">
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-3-1-1">
        <div></div>
        <div>
            <h3>Market Analysis</h3>
            <p>Leading players appeared to focus on generating impressive but disjointed video clips, placing less emphasis on connecting them into structured narrative, which positions themselves more as tools for visual experimentation and asset creation.</p>
            <p>To validate this hypothesis, I identified several leading players along the production cycle and established a set of criteria to assess their narrative capabilities.</p>
        </div>
    </div>
    <div class="grid grid-1-4-1">
        <div></div>
        <div class="image-container" style="padding: 0; overflow: hidden;">
            <img src="{{ '/images/opus/market-analysis.png' | relative_url }}" loading="lazy">
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-3-1-1">
        <div></div>
        <div>
            <h3>Brainstorming</h3>
            <p>The matrix above reveals a strategic opportunity: to differentiate by centering on storytelling support, aligning with the market gap and the team‚Äôs strengths, instead of competing on model performance.</p>
            <p>We brainstormed features that address narrative structure and creative flow more directly than model-centric competitors, using a mind map. Those deemed technically feasible and within design scope were marked as low-hanging fruit.</p>
        </div>
    </div>
    <div class="grid grid-1-4-1">
        <div></div>
        <div class="image-container">
            <img src="{{ '/images/opus/brainstorming.png' | relative_url }}" loading="lazy">
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-3-1-1">
        <div></div>
        <div>
            <h3>Wireframe</h3>
            <p>Subsequently, we explored how to organize the feature set through concrete interface paradigms and interaction patterns, forming two different directions.</p>
        </div>
    </div>
    <div class="grid grid-1-2-2-1">
        <div></div>
        <div class="list-container">
            <img src="{{ '/images/opus/wireframe-1.png' | relative_url }}" loading="lazy">
            <div>
                <h5>Storyboard</h5>
                <p>A visual tool used by filmmakers and animators to pre-visualize and plan a production clearly and efficiently, e.g., Toon Boom Storyboard.</p>
            </div>
        </div>
        <div class="list-container">
            <img src="{{ '/images/opus/wireframe-2.png' | relative_url }}" loading="lazy">
            <div>
                <h5>Infinite Canvas</h5>
                <p>A modular approach used by domain experts to design and execute complex systems visually, e.g., Grasshopper, Unreal Engine.</p>
            </div>
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-3-1-1">
        <div></div>
        <div>
            <h3>Concept Testing</h3>
            <p>Although the node-based interface initially intrigued the team, particularly designers and engineers, I facilitated an asynchronous workshop to gather insights cross-functionally and evaluate its viability.</p>
        </div>
    </div>
    <div class="grid grid-1-4-1">
        <div></div>
        <div class="image-container">
            <img src="{{ '/images/opus/concept-testing.png' | relative_url }}" loading="lazy">
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-3-1-1">
        <div></div>
        <div>
            <h3 class="np">Insights</h3>
            <p>The affinity mapping revealed that implementing such an architecture would require substantial engineering refactoring and invited critical concerns across technical, usability, and strategic dimensions.</p>
            <p>As a result, we deprioritized this option and redirected our focus toward the more feasible storyboard-based alternative.</p>
        </div>
    </div>
    <div class="grid grid-1-4-1">
        <div></div>
        <div class="card-list">
            <div class="card">
                <h5>ü§π Technical Complexity</h5>
                <p>Requires each cell to be developed standalone yet communicative, and the magnitude of potential cell combinations exponentially poses challenges in scalability, agility, and version control.</p>
            </div>
            <div class="card">
                <h5>ü§Ø Usability Uncertainty</h5>
                <p>Introduces flexibility with larger possibility of choice paralysis and increased cognitive load, which may alienate users with a fragmented, unpredictable, and delayed experience.</p>
            </div>
            <div class="card">
                <h5>üìâ Managerial Misalignment</h5>
                <p>Demands significant resources in labor, capital, and time for development and operation, potentially resulting in delays, shifts, or failures in achieving long-term strategic goals.</p>
            </div>
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-4-1">
        <div></div>
        <div>
            <h3>Prototype 1</h3>
            <div class="p-l">Introduced an intermediary step of text-to-image generation to stabilize the creative workflow, enabling users to preview keyframes and iterate on their sequence, timing, and narrative logic in areas where models typically fall short.</div>
        </div>
    </div>
</section>

<section class="full-width-bg" style="background-color: {{ page.color }};">
    <div class="flex-row">
        <div class="list-container">
            <img src="{{ '/images/opus/prototype-1-1.png' | relative_url }}" loading="lazy">
            <div>
                <h5>Prompt</h5>
                <p>Enrich the user input with storytelling techniques to produce a complete, engaging screenplay.</p>
            </div>
        </div>
        <div class="list-container">
            <img src="{{ '/images/opus/prototype-1-2.png' | relative_url }}" loading="lazy">
            <div>
                <h5>Screenplay</h5>
                <p>Parse the screenplay into shot-by-shot scripts with structured metadata to guide text-to-image generation.</p>
            </div>
        </div>
        <div class="list-container">
            <img src="{{ '/images/opus/prototype-1-3.png' | relative_url }}" loading="lazy">
            <div>
                <h5>Storyboard</h5>
                <p>Tweak keyframes, voiceover, and animation settings to better align with the user‚Äôs creative intent.</p>
            </div>
        </div>
        <div class="list-container">
            <img src="{{ '/images/opus/prototype-1-4.png' | relative_url }}" loading="lazy">
            <div>
                <h5>Slideshow</h5>
                <p>Simulate the structure and pacing of the final video to reduce uncertainty in image-to-video generation.</p>
            </div>
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-3-1-1">
        <div></div>
        <div>
            <h3>Usability Testing 1</h3>
            <p>Since I hypothesized multiple user segments, I recruited a slightly larger sample of 8 participants, including vloggers, content aggregators, enterprise marketers, and filmmakers.</p>
            <p>I tested this prototype to identity the main usability and functionality issues, along with a screener survey to assess the <b>usage intensity</b>, i.e., how each participant might use the proposed feature in their routine.</p>
        </div>
    </div>
    <div class="grid grid-1-4-1">
        <div></div>
        <div class="image-container">
            <img src="{{ '/images/opus/usability-testing-1-1.png' | relative_url }}" loading="lazy">
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-3-1-1">
        <div></div>
        <div>
            <h3 class="np">Insights</h3>
            <p>Looking closely, I found that even feedback within the same group often expressed conflicting views on what needed improvement.</p>
            <p>To make sense of those seemingly irreconcilable contradictions, I first examined the underlying intent behind each request, and then reshuffled them by <b>high-level goals</b>‚Äîthe broader needs encompassing possibly divergent user behaviors and expectations.</p>
        </div>
    </div>
    <div class="grid grid-1-4-1">
        <div></div>
        <div class="card-list">
            <div class="card">
                <h5>‚åõÔ∏è Efficiency</h5>
                <p>Reduce time, effort, financial cost, and cognitive friction by providing readable information, an intuitive interface, and a streamlined, user-friendly workflow.</p>
            </div>
            <div class="card">
                <h5>üìê Consistency</h5>
                <p>Enable a coherent narrative and stable visual identity across frames, while allowing reasonable variation to support continuity in action, time, and space.</p>
            </div>
            <div class="card">
                <h5>üïπ Adaptability</h5>
                <p>Support varied intents and use cases through rich customization options, flexible control over outputs and workflows, and a context-aware, responsive system.</p>
            </div>
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-3-1-1">
        <div></div>
        <div>
            <h3>Problem Statement</h3>
            <p>Before fully understanding user needs, workflows, or success criteria, we began with a straightforward yet knowingly simplistic problem framing based on client‚Äôs request, aiming to integrate a text-to-video feature to the current product. With high-level goals that emerged above, I refined the initially rough question as follows:</p>
        </div>
    </div>
    <div class="grid grid-1-4-1">
        <div></div>
        <div class="p-l" style="margin-bottom: 0px;">
            <blockquote>How might we empower content creators to quickly and easily translate their scripts into reliably high-quality videos while accommodating diverse scenarios?</blockquote>
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-3-1-1">
        <div></div>
        <div>
            <h3 class="np">Insights</h3>
            <p>The observed conflicting feedback unveiled divergent user expectations and behaviors, rooted in how users conceptualized the shared high-level goals differently and hence their distinct positions on value trade-offs. This indicates multiple user segments, which should be logically inferable by their clustering on these trade-off spectrums.</p>
            <p>Therefore, I mapped all those stickers onto two axes that represent core tensions in users‚Äô decision-making: <b>Cost vs. Perceived Quality</b> and <b>User Agency vs. Automation</b>.</p>
        </div>
    </div>
    <div class="grid grid-1-4-1">
        <div></div>
        <div class="image-container">
            <img src="{{ '/images/opus/usability-testing-1-2.png' | relative_url }}" loading="lazy">
        </div>
    </div>
    <div class="grid grid-1-3-1-1">
        <div></div>
        <div>
            <p>All stickers are distributed diagonally from the upper-left to lower-right quadrants, with high and low usage intensity clustering at opposite ends, demonstrating the following insights:</p>
        </div>
    </div>
    <div class="grid grid-1-4-1">
        <div></div>
        <div class="card-list">
            <div class="card">
                <h5>1Ô∏è‚É£ We Don‚Äôt Trust AI</h5>
                <p>The negative correlation between perceived quality and automation validates the hypothesis that users associate strong outputs with manual control, implying limited trust in fully automated systems to deliver professional results.</p>
            </div>
            <div class="card">
                <h5>2Ô∏è‚É£ User Segmentation</h5>
                <p>The polarization between users with different usage intensity reveals two user groups that vary in positions on the two value axes, i.e., the expectation for production commitment and outcomes, and the preference for interaction.</p>
            </div>
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-3-1-1">
        <div></div>
        <div>
            <h3>Personas</h3>
            <p>Based on user segmentation, I developed two personas and mapped their differences across multiple dimensions of the two core tensions.</p>
            <p>Original creators are typically users with a high level of creative expertise, such as indie filmmakers and animators. Derivative creators are more likely users with distribution-driven priorities, including influencers and content aggregators.</p>
        </div>
    </div>
    <div class="grid grid-1-2-2-1">
        <div></div>
        <div class="list-container">
            <img src="{{ '/images/opus/persona-1.png' | relative_url }}" loading="lazy">
            <div>
                <h5>Original Creator</h5>
                <p>Seek to maintain creative authorship while achieving high-quality outputs; cautious of full automation and perceive the tool as an extension.</p>
            </div>
        </div>
        <div class="list-container">
            <img src="{{ '/images/opus/persona-2.png' | relative_url }}" loading="lazy">
            <div>
                <h5>Derivative Creator</h5>
                <p>Aim to produce acceptable outputs with minimal input; willing to delegate complex tasks to the system and view the tool as a replacement.</p>
            </div>
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-4-1">
        <div></div>
        <div>
            <h3>Prototype 2</h3>
            <div class="p-l">
                We improved clarity and workflow efficiency through both structural and functional enhancements, including a redesigned layout, surfaced global settings, and centralized asset control to support faster, more consistent text-to-image generation.
            </div>
        </div>
    </div>
</section>

<section class="full-width-bg" style="background-color: {{ page.color }};">
    <div class="grid grid-6">
        <h4>I. Layout</h4>
    </div>
    <div class="grid grid-3-3">
        <div class="list-container">
            <div class="before">
                <img src="{{ '/images/opus/I1-1B.png' | relative_url }}" loading="lazy">
            </div>
            <div class="before">
                <h5>BEFORE</h5>
                <p>Arranged shots horizontally, causing confusion due to misalignment between the container and slider lengths, which conflicted with standard scrolling behavior.</p>
            </div>
        </div>
        <div class="list-container">
            <div class="after">
                <video width="100%" height="auto" autoplay loop muted>
                    <source src="/images/opus/I1-1A.mp4" type="video/mp4" loading="lazy">
                </video>
            </div>
            <div class="after">
                <h5>AFTER</h5>
                <p>Switched to a vertical layout with two modes, and collapsed shot editing options with hover effects to reduce cognitive load through prioritized information display.</p>
            </div>
        </div>
    </div>
    <div class="grid grid-6">
        <h4>II. Customization</h4>
    </div>
    <div class="grid grid-3-3">
        <div class="list-container">
            <div class="before">
                <img src="{{ '/images/opus/I1-2-1B.png' | relative_url }}" loading="lazy">
            </div>
            <div class="before">
                <h5>BEFORE</h5>
                <p>Required manual configuration of global settings each time via a low-discoverability button, leading to repetitive setup and frequent oversights.</p>
            </div>
        </div>
        <div class="list-container">
            <div class="after">
                <img src="{{ '/images/opus/I1-2-1A.png' | relative_url }}" loading="lazy">
            </div>
            <div class="after">
                <h5>AFTER</h5>
                <p>Displayed global settings in a prominent sidebar and introduced both predefined and customizable templates to streamline setup and ensure consistency.</p>
            </div>
        </div>
    </div>
    <div class="grid grid-3-3">
        <div class="list-container">
            <div class="before">
                <img src="{{ '/images/opus/I1-2-2B.png' | relative_url }}" loading="lazy">
            </div>
            <div class="before">
                <h5>BEFORE</h5>
                <p>Required extensive manual effort to tweak shots individually in order to maintain visual consistency across shots.</p>
            </div>
        </div>
        <div class="list-container">
            <div class="after">
                <video width="100%" height="auto" autoplay loop muted>
                    <source src="/images/opus/I1-2-2A.mp4" type="video/mp4" loading="lazy">
                </video>
            </div>
            <div class="after">
                <h5>AFTER</h5>
                <p>Extracted shared assets from the script automatically, enabling centralized control for easy insertion and batch-level tweaking.</p>
            </div>
        </div>
    </div>
    <div class="grid grid-6">
        <h4>III. Inline Editing</h4>
    </div>
    <div class="grid grid-3-3">
        <div class="list-container">
            <div class="before">
                <img src="{{ '/images/opus/I1-3B.png' | relative_url }}" loading="lazy">
            </div>
            <div class="before">
                <h5>BEFORE</h5>
                <p>Applied AI-assisted text enhancements to the entire text area, altering unrelated content and lacking support for targeted control.</p>
            </div>
        </div>
        <div class="list-container">
            <div class="after">
                <img src="{{ '/images/opus/I1-3A.png' | relative_url }}" loading="lazy">
            </div>
            <div class="after">
                <h5>AFTER</h5>
                <p>Introduced a floating toolbar that allows users to select specific text segments for focused, instruction-based modifications in the editor.</p>
            </div>
        </div>
    </div>
    <div class="grid grid-6">
        <h4>IV. Separate Workflow</h4>
    </div>
    <div class="grid grid-3-3">
        <div class="list-container">
            <div class="before">
                <img src="{{ '/images/opus/I1-4B.png' | relative_url }}" loading="lazy" style="background-color: var(--background);">
            </div>
            <div class="before">
                <h5>BEFORE</h5>
                <p>Followed a linear path with a fixed entry point, assuming all users start from scratch and proceed through every editing stage.</p>
            </div>
        </div>
        <div class="list-container">
            <div class="after">
                <img src="{{ '/images/opus/I1-4A.png' | relative_url }}" loading="lazy" style="background-color: var(--background);">
            </div>
            <div class="after">
                <h5>AFTER</h5>
                <p>Added conditional branching and early skip options to bypass unnecessary editing steps based on user readiness, reducing the minimum required steps.</p>
            </div>
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-3-1-1">
        <div></div>
        <div>
            <h3>Usability Testing 2</h3>
            <p>I tested the updated prototype and initially categorized feedback by improvement areas. I then reclassified it using the previously identified high-level goals. However, several items didn‚Äôt fit any known category.</p>
        </div>
    </div>
    <div class="grid grid-1-4-1">
        <div></div>
        <div class="image-container">
            <img src="{{ '/images/opus/usability-testing-2.png' | relative_url }}" loading="lazy">
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-3-1-1">
        <div></div>
        <div>
            <h3 class="np">Insights</h3>
            <p>The uncategorized feedback reveals an unstated high-level goal in the previous round, i.e., <b>transparency</b>‚Äîa deeper understanding of the system‚Äôs operations and decisions, and hence more informed and targeted manipulation.</p>
        </div>
    </div>
    <div class="grid grid-1-4-1">
        <div></div>
        <div class="card-list">
            <div class="card">
                <h5>1Ô∏è‚É£ Processing Logic Exposure</h5>
                <p>Demystify how inputs and parameters are interpreted, e.g., establish a visually clear cause-effect relationship between script segments and corresponding generated shots.</p>
            </div>
            <div class="card">
                <h5>2Ô∏è‚É£ Cognitive Load Distribution</h5>
                <p>Offer progressive disclosure of information to guide user interactions, e.g., simplify complex, effort-intensive prompting by disassembling it into smaller, manageable pieces via structured input fields.</p>
            </div>
            <div class="card">
                <h5>3Ô∏è‚É£ Human-in-the-Loop Moment</h5>
                <p>Integrate deliberate checkpoints where users can validate, revise, or override AI outputs, e.g., include undo/redo capabilities and history log to revert states or track changes.</p>
            </div>
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-4-1">
        <div></div>
        <div>
            <h3>Prototype 3</h3>
            <div class="p-l">
                We included transparency as a new evaluation lens while continuing to improve core usability through fine-grained refinements, including clarified interface hierarchy and interaction logic, flexible preview controls, and more informative version tracking.
            </div>
        </div>
    </div>
</section>

<section class="full-width-bg" style="background-color: {{ page.color }};">
    <div class="grid grid-6">
        <h4>I. Script Reformatting</h4>
    </div>
    <div class="grid grid-3-3">
        <div class="list-container">
            <div class="before">
                <video width="100%" height="auto" autoplay loop muted>
                    <source src="/images/opus/I2-1-1B.mp4" type="video/mp4" loading="lazy">
                </video>
            </div>
            <div class="before">
                <h5>BEFORE</h5>
                <p>Relied on plain text with minimal markdown-style grammar, confusing non-technical users and necessitating model‚Äôs semantic understanding.</p>
            </div>
        </div>
        <div class="list-container">
            <div class="after">
                <video width="100%" height="auto" autoplay loop muted>
                    <source src="/images/opus/I2-1-1A.mp4" type="video/mp4" loading="lazy">
                </video>
            </div>
            <div class="after">
                <h5>AFTER</h5>
                <p>Added a reformat option to declare key elements with symbolic tags, improving frontend styling and generative performance.</p>
            </div>
        </div>
    </div>
    <div class="grid grid-3-3">
        <div class="list-container">
            <div class="before">
                <video width="100%" height="auto" autoplay loop muted>
                    <source src="/images/opus/I2-1-2B.mp4" type="video/mp4" loading="lazy">
                </video>
            </div>
            <div class="before">
                <h5>BEFORE</h5>
                <p>Displayed all options as buttons with icons and text labels, and provided sliders to adjust tone and length, resulting in redundant choices and unnecessary clicks.</p>
            </div>
        </div>
        <div class="list-container">
            <div class="after">
                <video width="100%" height="auto" autoplay loop muted>
                    <source src="/images/opus/I2-1-2A.mp4" type="video/mp4" loading="lazy">
                </video>
            </div>
            <div class="after">
                <h5>AFTER</h5>
                <p>Replaced label-heavy buttons with grouped icon buttons, differentiated prompt input from function controls, and removed redundant two-step interactions.</p>
            </div>
        </div>
    </div>
    <div class="grid grid-6">
        <h4>II. Shot Editing</h4>
    </div>
    <div class="grid grid-3-3">
        <div class="list-container">
            <div class="before">
                <img src="{{ '/images/opus/I2-2-1B.png' | relative_url }}" loading="lazy" style="background-color: var(--background);">
            </div>
            <div class="before">
                <h5>BEFORE</h5>
                <p>Misarranged controls with an illogical information architecture, juxtaposed unrelated functions and nested options that should have remained parallel.</p>
            </div>
        </div>
        <div class="list-container">
            <div class="after">
                <img src="{{ '/images/opus/I2-2-1A.png' | relative_url }}" loading="lazy" style="background-color: var(--background);">
            </div>
            <div class="after">
                <h5>AFTER</h5>
                <p>Reorganized controls by target objects and logical relationships across the floating toolbar and modal, and removed redundant buttons.</p>
            </div>
        </div>
    </div>
    <div class="grid grid-3-3">
        <div class="list-container">
            <div class="before">
                <img src="{{ '/images/opus/I2-2-2B.png' | relative_url }}" loading="lazy">
            </div>
            <div class="before">
                <h5>BEFORE</h5>
                <p>Opened a new page with a disjointed layout where the trigger button didn‚Äôt align with the output keyframe, undermining traceability between the trigger and the result.</p>
            </div>
        </div>
        <div class="list-container">
            <div class="after">
                <img src="{{ '/images/opus/I2-2-2A.png' | relative_url }}" loading="lazy">
            </div>
            <div class="after">
                <h5>AFTER</h5>
                <p>Flattened the page hierarchy using modals and in-textarea dropdowns to establish a more intuitive cause-and-effect relationship.</p>
            </div>
        </div>
    </div>
    <div class="grid grid-3-3">
        <div class="list-container">
            <div class="before">
                <img src="{{ '/images/opus/I2-2-3B.png' | relative_url }}" loading="lazy">
            </div>
            <div class="before">
                <h5>BEFORE</h5>
                <p>Generated audio tracks exclusively from voiceover input, limiting applicability to genres like vlogs and commentary where narrative closely follows the visuals.</p>
            </div>
        </div>
        <div class="list-container">
            <div class="after">
                <video width="100%" height="auto" autoplay loop muted>
                    <source src="/images/opus/I2-2-3A.mp4" type="video/mp4" loading="lazy">
                </video>
            </div>
            <div class="after">
                <h5>AFTER</h5>
                <p>Separated dialogue from voiceover to support formats like feature films, where audio often diverges from visuals and voiceover alone is insufficient.</p>
            </div>
        </div>
    </div>
    <div class="grid grid-6">
        <h4>III. Preview Mode</h4>
    </div>
    <div class="grid grid-3-3">
        <div class="list-container">
            <div class="before">
                <img src="{{ '/images/opus/I2-3-1B.png' | relative_url }}" loading="lazy">
            </div>
            <div class="before">
                <h5>BEFORE</h5>
                <p>Allowed preview only at the final step via an ambiguously labeled button, with no option to set starting points, discouraging early identification of issues.</p>
            </div>
        </div>
        <div class="list-container">
            <div class="after">
                <video width="100%" height="auto" autoplay loop muted>
                    <source src="/images/opus/I2-3-1A.mp4" type="video/mp4" loading="lazy">
                </video>
            </div>
            <div class="after">
                <h5>AFTER</h5>
                <p>Introduced a slideshow mode that simulates the final output‚Äôs pacing and structure before committing, with flexible back-and-forth switching between modes.</p>
            </div>
        </div>
    </div>
    <div class="grid grid-6">
        <h4>IV. Version Control</h4>
    </div>
    <div class="grid grid-3-3">
        <div class="list-container">
            <div class="before">
                <img src="{{ '/images/opus/I2-3-2B.png' | relative_url }}" loading="lazy">
            </div>
            <div class="before">
                <h5>BEFORE</h5>
                <p>Kept a flat version control system that recorded all generation variations, offering little value for tracking meaningful changes or refining prompts.</p>
            </div>
        </div>
        <div class="list-container">
            <div class="after">
                <img src="{{ '/images/opus/I2-3-2A.png' | relative_url }}" loading="lazy">
            </div>
            <div class="after">
                <h5>AFTER</h5>
                <p>Maintained an iteration log that highlights differences compared to the last selected version, enabling more informed and focused revisions.</p>
            </div>
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-4-1">
        <div></div>
        <div>
            <h2>Retrospect</h2>
            <div class="p-l">
                Trust-building surfaced as a recurring theme, not only in designing human-AI collaborative models that foster user confidence, but also in establishing credibility and exposure within the team, thereby driving iterative direction and securing alignment as a mercenary with limited visibility and resources.
            </div>
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-3-1-1">
        <div></div>
        <div>
            <h3>Takeaways</h3>
            <p>Lessons learned emerged not only about users‚Äô mental models and behaviors, but also about coping with ambiguity in social dynamics, research methodologies, and practical design techniques.</p>
        </div>
    </div>
    <div class="grid grid-1-4-1">
        <div></div>
        <div class="card-list">
            <div class="card">
                <h5>1Ô∏è‚É£ Billiard Method</h5>
                <p>When direct peer support is absent, maintain momentum by engaging stand-by colleagues with something tangible in hands for constructive feedback.</p>
            </div>
            <div class="card">
                <h5>2Ô∏è‚É£ Upfront Benchmarking</h5>
                <p>When A/B testing isn‚Äôt available for multiple choices, define evaluative criteria that derive from core objectives with specific, actionable, and measurable rubrics.</p>
            </div>
            <div class="card">
                <h5>3Ô∏è‚É£ Opening Black Box</h5>
                <p>Provide transparency into AI‚Äôs decision-making, rather than simply presenting end-products, allowing users to understand how inputs translate into outputs.</p>
            </div>
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-3-1-1">
        <div></div>
        <div>
            <h3>Ways Forward</h3>
            <p>Looking ahead, our future endeavors should take a holistic consideration of various dimensions in design, development, and strategy, to adapt to evolving product demands and market dynamics.</p>
        </div>
    </div>
    <div class="grid grid-1-4-1">
        <div></div>
        <div class="card-list">
            <div class="card">
                <h5>1Ô∏è‚É£ Waiting Experience</h5>
                <p>Implement mechanisms like progressive disclosure or dynamic skeleton, keeping users engaged during processing time, reducing perceived latency.</p>
            </div>
            <div class="card">
                <h5>2Ô∏è‚É£ Ecosystem Connectivity</h5>
                <p>Integrate with existing captioning workflows and seamlessly merge into the broader post-production ecosystem by enabling export to popular NLEs.</p>
            </div>
            <div class="card">
                <h5>3Ô∏è‚É£ Pricing Structure</h5>
                <p>Explore new monetization strategies that fit increased computational costs and value delivered, e.g., tiered subscriptions, pay-per-export, and enterprise licensing.</p>
            </div>
        </div>
    </div>
</section>

<section>
    <div class="grid grid-1-3-1-1">
        <div></div>
        <div>
            <h3>Hindsights</h3>
            <p>The company has successfully raised $30M in Series A in August 2024 and $20M in Series B in March 2025, but ultimately chose not to ship the storyboard feature, likely due to a strategic pivot toward monetizable, lower-risk enhancements to its core captioning feature amid the intensifying competition.</p>
        </div>
    </div>
    <div class="grid grid-1-4-1">
        <div></div>
        <div class="card-list">
            <div class="card">
                <h5>üöÄ Intensifying Competition</h5>
                <p>With research-driven startups like Sand.ai raising technical benchmarks and niche players like Katalist.ai gaining early traction, the increasingly complex landscape made it more prudent to focus on strengthening current revenue drivers before expanding into new verticals with fragmented use cases.</p>
            </div>
            <div class="card">
                <h5>üìä Proposed Success Metrics</h5>
                <p>If the feature had been shipped, at launched, track activation rate, export rate, and usage frequency to measure evaluate initial user engagement and to identify early signals of perceived value. Over time, monitor user retention lift and conversion rate to evaluate long-term business impact and sustained behavior change.</p>
            </div>
        </div>
    </div>
</section>